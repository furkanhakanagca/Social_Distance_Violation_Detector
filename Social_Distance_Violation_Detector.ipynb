{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social_Distance_Violation_Detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPf9XbpPY7h4",
        "outputId": "f713b7af-c61c-4d4d-a7ef-487e0bec9149"
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUWG8k1MY_Co"
      },
      "source": [
        "#load video\n",
        "def load_video(video_path):\n",
        "    vid = cv2.VideoCapture(video_path)\n",
        "    if vid.isOpened()==False:\n",
        "        print(\"Error opening video!\")\n",
        "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(r'Kadıköy-Bahariye-Caddesi-15-01-2000-2005_out.avi', codec, fps, (width, height))\n",
        "    return vid, out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQhnIJ8VY-_9"
      },
      "source": [
        "#get distance of each pair of boxes\n",
        "def get_distance(midpos,boxes_num):\n",
        "    dist=np.zeros((boxes_num,boxes_num))\n",
        "    for i in range(boxes_num):\n",
        "        for j in range(boxes_num):\n",
        "            if i!=j:\n",
        "                dist[i][j]=distance.euclidean(midpos[i],midpos[j])\n",
        "                print(dist[i][j])\n",
        "    return dist;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb7SD19fY-9L"
      },
      "source": [
        "#process frames one by one\n",
        "def process_frames(vid,detector,out):\n",
        "    frame_num=0\n",
        "    while True:\n",
        "        return_value, frame = vid.read()\n",
        "        if return_value:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            image = Image.fromarray(frame)\n",
        "        else:\n",
        "            if frame_num > 0:\n",
        "                print(\"Video processing complete\")\n",
        "                break\n",
        "            else:\n",
        "                raise ValueError(\"No image! Try with another video format\")\n",
        "     \n",
        "        image_data = cv2.resize(frame, (512, 512))\n",
        "        image_data = image_data[np.newaxis, ...].astype(np.ubyte)\n",
        "        batch_data = tf.constant(image_data)\n",
        "    \n",
        "        #inference\n",
        "        detections = detector(batch_data)\n",
        "    \n",
        "        classes = detections['detection_classes']\n",
        "        boxes= detections['detection_boxes']\n",
        "        scores= detections['detection_scores']\n",
        "       \n",
        "        classes=tf.reshape(classes,[-1]);\n",
        "        scores=tf.reshape(scores,[-1]);\n",
        "        boxes=tf.reshape(boxes,[-1,4])\n",
        "    \n",
        "        #get person with score exceeding the threshold\n",
        "        ind=np.where((classes==1) & (scores>0.30))\n",
        "        if len(ind[0]) == 0:\n",
        "            continue;\n",
        "        person_boxes=tf.gather(boxes,ind);\n",
        "        person_boxes=tf.reshape(person_boxes,[-1,4])\n",
        "        person_num=len(person_boxes)\n",
        "    \n",
        "        #draw bounding boxes\n",
        "        image_h, image_w, _ = frame.shape\n",
        "        image_hw = tf.constant([image_h,image_w,image_h,image_w],dtype=tf.float32)\n",
        "        image_hw = tf.broadcast_to(image_hw,person_boxes.shape)\n",
        "        person_boxes = person_boxes * image_hw\n",
        "    \n",
        "        bbox_line = int(min(image_h,image_w) / 100)\n",
        "        bbox_color=(255,0,0) \n",
        "        midpos=np.zeros((person_num,2))\n",
        "        for i in range(person_num):\n",
        "            coor=list(person_boxes[i])  \n",
        "            c1, c2 = (coor[1], coor[0]), (coor[3], coor[2])\n",
        "            #get middle points of box\n",
        "            midpos[i][0]=(coor[1]+coor[3])/2\n",
        "            midpos[i][1]=(coor[0]+coor[2])/2\n",
        "            cv2.rectangle(frame, c1, c2, bbox_color, bbox_line) \n",
        "        dist=get_distance(midpos,person_num)\n",
        "        for i in range(person_num):\n",
        "            coor_i=list(person_boxes[i])\n",
        "            boxw_i=coor_i[3]-coor_i[1]\n",
        "            boxh_i=coor_i[2]-coor_i[0]\n",
        "            c1_i,c2_i=(coor_i[1],coor_i[0]),(coor_i[3],coor_i[2])\n",
        "            for j in range(i+1,person_num):\n",
        "                coor_j=list(person_boxes[j])\n",
        "                boxw_j=coor_j[3]-coor_j[1]\n",
        "                boxh_j=coor_j[2]-coor_j[0]\n",
        "                c1_j,c2_j=(coor_j[1],coor_j[0]),(coor_j[3],coor_j[2])\n",
        "                if abs(coor_i[2]-coor_j[2])<min(boxw_i,boxw_j)/5 and dist[i][j]<boxw_j+boxw_i:\n",
        "                    cv2.rectangle(frame,c1_i,c2_i,(0,0,255),bbox_line)\n",
        "                    cv2.rectangle(frame,c1_j,c2_j,(0,0,255),bbox_line)\n",
        "        result = np.asarray(frame)\n",
        "        #cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
        "        #cv2.imshow(\"result\", result)\n",
        "        #if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
        "        out.write(result)\n",
        "        frame_num=frame_num+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOvjXpBGY-6h"
      },
      "source": [
        "#load model\n",
        "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/d2/1\")\n",
        "#load video\n",
        "vid, out = load_video(r'/content/drive/MyDrive/Social Distancing Video/Kadıköy-Bahariye-Caddesi-15-01-2000-2005.avi')\n",
        "process_frames(vid,detector,out)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}